{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Restaurant_Reviews_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2OnEw_69a-1s",
        "x3sbw-fkcfFH",
        "Pzegsn8vc9It",
        "cUYVCF5WdR7C",
        "GPmC4gmMen5d",
        "O6EoLzOefY4v",
        "ysa23wOof6ml",
        "vKqOk79jgbQR",
        "IqnWvgCjg5e8",
        "uAngacZmhXCH",
        "txe-QliphdIE",
        "ccU6u_00iss2",
        "BQXYZlEhjWO-",
        "FY0ZIMNVjmQo",
        "9I1tfKTBj9vC",
        "f0nya5S5kX9w",
        "rV9J6xgqkwVs"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading and Preprocessing"
      ],
      "metadata": {
        "id": "2OnEw_69a-1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "2MBBfpyRSazv"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At5O8PDGTY-K",
        "outputId": "fe5848c5-d15a-4252-b723-e9a075542628"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Download helper functions script\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "# Import series of helper functions for the notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXd-dAENSaxH",
        "outputId": "c10e13f8-cbe8-40c4-cbc6-1d44836abd66"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-21 17:41:45--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py.1’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-06-21 17:41:45 (94.8 MB/s) - ‘helper_functions.py.1’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yelp_data = pd.read_csv('/drive/MyDrive/NLP Datasets/yelp_ratings.csv')"
      ],
      "metadata": {
        "id": "uy4BLXSpRO0P"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yelp_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhDLKLpijZcP",
        "outputId": "e42696b9-4e70-486d-9f17-e650544cfb42"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44530, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yelp_data.head(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "yUUxTkqqja41",
        "outputId": "1bca4d0c-aaa8-4cb3-b82b-82746d121a4a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 text  stars  sentiment\n",
              "0   Total bill for this horrible service? Over $8G...    1.0          0\n",
              "1   I *adore* Travis at the Hard Rock's new Kelly ...    5.0          1\n",
              "2   I have to say that this office really has it t...    5.0          1\n",
              "3   Went in for a lunch. Steak sandwich was delici...    5.0          1\n",
              "4   Today was my second out of three sessions I ha...    1.0          0\n",
              "5   I'll be the first to admit that I was not exci...    4.0          1\n",
              "6   This place has gone down hill.  Clearly they h...    1.0          0\n",
              "7   I was really looking forward to visiting after...    2.0          0\n",
              "8   Like walking back in time, every Saturday morn...    4.0          1\n",
              "9   Walked in around 4 on a Friday afternoon, we s...    1.0          0\n",
              "10  Wow. So surprised at the one and two star revi...    4.0          1\n",
              "11  Michael from Red Carpet VIP is amazing ! I rea...    4.0          1\n",
              "12  I cannot believe how things have changed in 3 ...    1.0          0\n",
              "13  You can't really find anything wrong with this...    5.0          1\n",
              "14  Great lunch today. Staff was very helpful in a...    4.0          1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eeaf81ed-d830-4616-8f9c-5573f25f0b95\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>stars</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Total bill for this horrible service? Over $8G...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I have to say that this office really has it t...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Today was my second out of three sessions I ha...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>I'll be the first to admit that I was not exci...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>This place has gone down hill.  Clearly they h...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>I was really looking forward to visiting after...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Like walking back in time, every Saturday morn...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Walked in around 4 on a Friday afternoon, we s...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Wow. So surprised at the one and two star revi...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Michael from Red Carpet VIP is amazing ! I rea...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>I cannot believe how things have changed in 3 ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>You can't really find anything wrong with this...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Great lunch today. Staff was very helpful in a...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eeaf81ed-d830-4616-8f9c-5573f25f0b95')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eeaf81ed-d830-4616-8f9c-5573f25f0b95 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eeaf81ed-d830-4616-8f9c-5573f25f0b95');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many examples of each class?\n",
        "yelp_data.sentiment.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOpmpXj_jq7a",
        "outputId": "7db0e67c-7aad-434f-b3d0-19773320b407"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    33331\n",
              "0    11199\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yelp_data.drop(\"stars\", axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "EPG9AzkakOdX"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yelp_data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hFIQuvQnkih7",
        "outputId": "a8098c08-cb17-4f29-ec6b-c42c77405993"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  sentiment\n",
              "0  Total bill for this horrible service? Over $8G...          0\n",
              "1  I *adore* Travis at the Hard Rock's new Kelly ...          1\n",
              "2  I have to say that this office really has it t...          1\n",
              "3  Went in for a lunch. Steak sandwich was delici...          1\n",
              "4  Today was my second out of three sessions I ha...          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b6db6eb-9011-48ed-946a-5058773d698b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Total bill for this horrible service? Over $8G...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I have to say that this office really has it t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Today was my second out of three sessions I ha...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b6db6eb-9011-48ed-946a-5058773d698b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9b6db6eb-9011-48ed-946a-5058773d698b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9b6db6eb-9011-48ed-946a-5058773d698b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled = yelp_data.sample(frac=1, random_state=42) # shuffle with random_state=42 for reproducibility\n",
        "train_df_shuffled.shape, train_df_shuffled.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIcyqG2mYlvR",
        "outputId": "209de7a2-3d3d-4606-999b-5804f6beb9c0"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((44530, 2),\n",
              "                                                     text  sentiment\n",
              " 10092  This review is for Wynn Fitness Richmond Hill,...          1\n",
              " 26633  Great little dive with cheap drinks. The Burge...          1\n",
              " 29324  The pho it's self isn't bad at all, very littl...          0\n",
              " 15822  I love going there when I want to host a nice ...          1\n",
              " 6631   I ordered and after 40 minutes I get a text th...          0)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's visualize some random training examples\n",
        "import random\n",
        "random_index = random.randint(0, len(yelp_data)-5) # create random indexes not higher than the total number of samples\n",
        "for row in train_df_shuffled[[\"text\", \"sentiment\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, sentiment = row\n",
        "  print(f\"Target: {sentiment}\", \"(positive review)\" if sentiment > 0 else \"(negative review)\")\n",
        "  print(f\"Text: {text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BigsFJsqXdkN",
        "outputId": "d42367f7-d035-44df-e445-1fdc51912bfd"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0 (negative review)\n",
            "Text: They deserve ZERO STARS but Yelp doesn't offer that option. I've used this car wash several times out of convenience,  however the service and quality of work is always the same...TERRIBLE!  Even when you call them out on the lack of effort, their none contributing to society, waste of space employees still do a s@#ty. \n",
            "\n",
            "If I'm not clear, I'm saying YOU SUCK FULL CIRCLE...\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (negative review)\n",
            "Text: I have my own Nonna so when I found out that this place was run by old-school Italians I was overjoyed.  My experience with them, after many visits, is that despite their kind demeanour the food is nothing like home cooking.  The sauce is so heavy on the oregano and tinned tomato concentrate and it tastes as if they add sugar to reduce the acidity - very mangiacake. Because the sauce is so poor, their sandwiches taste like the ones you get Pizza Pizza.  Their chicken parmigianna is cafeteria-level.  Pepperoni pizza features pepperoni straight from the packaged cold cut aisle at No Frills.  The saving grace here is the primavera pizza, if you can stand the hour wait - this, at least, is reliable and decent.\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (positive review)\n",
            "Text: I went here for a burger and a side salad of Kale. Great flavor and presentation. The server was really friendly and helpful. My only complaint is that like many cavernous modern spaces with glass and high ceilings the noise of the filled up restaurant almost drowned out my lunch companion. Literally I almost resorted to passing notes at the table. Otherwise it is a solid lunch choice. Parking was readily available and free unlike going to the belly of the downtown Isthmus beast.\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (positive review)\n",
            "Text: Came here for brunch and everything really exceeded our expectations from the food's presentation to the meal itself, the bacon being the main standout. A perfect place!\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (positive review)\n",
            "Text: I highly recommend this place.   It isnt often that i slow down just so the meal lasts longer. This time i did.  I had the seafood  risoto.  It was wonderful.  It was packed with seafood - no skimping.  Everything blended into a wonderful  sauce that gathered in the bottom of the bowl - mmm just wonderful!  My companion had the fish stew; which hd really liked.\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(yelp_data[\"text\"].to_numpy(),\n",
        "                                                                            yelp_data[\"sentiment\"].to_numpy(),\n",
        "                                                                            test_size=0.2, # dedicate 10% of samples to validation set\n",
        "                                                                            random_state=42) # random state for reproducibility"
      ],
      "metadata": {
        "id": "0I7CUa-pXfRa"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysUx0ihHaj2k",
        "outputId": "0c2472a1-9c46-42aa-a41c-172a05544db8"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35624, 35624, 8906, 8906)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the first 10 training sentences and their labels\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbZrj9AiawnB",
        "outputId": "398daa0d-77bb-4d32-d48e-89a540077d1e"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['Great vegan options! The food is always fresh and prepared well. It can be a little crowded but the atmosphere is fun. One of my favorite places!',\n",
              "        'Hands down the best sushi place of town of markham. Hidden gem. This place has the greatest service. And the chef and the people that work here are always happy. The sushi portions are huge and delicious.',\n",
              "        \"Great food, but please don't lock your doors at 7:40 when you advertise being open until 8pm. I made a special trip for JJ's only to be met with a locked door and no notice of the change or practice.  Disappointing.  I'll definitely think twice next time I want a hot dog.\",\n",
              "        'Came here today for lunch ordered the chicken cho fun . My friend has the island chicken and we tried the spring rolls. Best sweet and sour sauce I have ever had and we got our food within minutes!',\n",
              "        \"Overall so delicious! Housemade chips are perfection. The guacamole is good, though definitely has crema mixed in, which I'd like to do without. \\nThe black beans and poblano rice are absolutely killer. I ordered the Latin Lover Shrimp. Though the sauce was supposed to be spicy, it wasn't in the least. Perfectly cooked shrimp, though the mushrooms were inedible because of the overwhelming smoke. \\nWill most definitely be returning! I'm hoping that they'll fix the seating... far too high for the table height, and generally just uncomfortable.\",\n",
              "        'Been a regular here for years. The dirty iced chai, wonderful staff and owner, and the awesome live bands make for an incredible little coffee shop in Cave Creek. The atmosphere is truly unique and one of a kind.',\n",
              "        'We were in town visiting and I knew from watching The Food Network that I wanted to stop here for the Mighty Macaroni! It did not disappoint.  My 17 year-old son and his friend loved the place too. Very fun and neat decor!',\n",
              "        'Solid spot with lots of technicians. I came here with my mom and we got mani/pedis. They are reasonably priced and I was happy with the service. I was impressed with how many pedicure chairs they have- a great spot if you have a group wanting to get nails done together.',\n",
              "        \"Dr. Picot has always been honest, courteous, and friendly. It amazes me how a dentist with probably a few thousand patients can remember our past conversations, my job, my wife, etc. He is always very personable and seems to basically pick up our conversation from where left of...6 months ago. And the work he has done for me has been excellent. \\n\\nDr. Picot has a high-tech office. He has a Cerec miller, which means he can create a crown in hour or so. My last dentist took 4 weeks for a permanent crown! His investment in technology is not only a time-saver, but also a means of relaxing while in the office (top of the line massaging dental chairs, cable TV in every room, digital x-rays, etc.). \\n\\nAside from the techie stuff, Dr. Picot was accommodating to my schedule today for an emergency to fix a cracked front tooth that happened last night, even though his office wasn't open today. He saw me today anyway, and took care of me to the highest extent while the office was technically closed. I am happy to be one of his patients and glad that I can depend on him!\",\n",
              "        'Excellent food. Very good price. We ordered more than 10 items, every single item was tasty and in large quantity.'],\n",
              "       dtype=object), array([1, 1, 0, 1, 1, 1, 1, 1, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text vectorization (tokenization)"
      ],
      "metadata": {
        "id": "quP3H54Pa68J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Use the default TextVectorization variables\n",
        "text_vectorizer = tf.keras.layers.TextVectorization(max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
        "                                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
        "                                                    split=\"whitespace\", # how to split tokens\n",
        "                                                    ngrams=None, # create groups of n-words?\n",
        "                                                    output_mode=\"int\", # how to map tokens to numbers\n",
        "                                                    output_sequence_length=None) # how long should the output sequence of tokens be?\n",
        "                                                    # pad_to_max_tokens=True) # Not valid if using max_tokens=None"
      ],
      "metadata": {
        "id": "E3LhnjiaazQ3"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find average number of tokens (words) in training Tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSYPga_XbN2j",
        "outputId": "0678ebab-2c81-44b7-beae-a1d76dfb7b3b"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "106"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now let's create another TextVectorization object using our custom parameters.**"
      ],
      "metadata": {
        "id": "vYwblsVUb1B6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "# Setup text vectorization with custom variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ],
      "metadata": {
        "id": "K7M-p7p8bQZT"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "ohyOTKldb47F"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjN-nFdOcRw1",
        "outputId": "d18b42ad-f4d1-4dbf-94b7-0a8ccbfb2ff2"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[ 441,    5, 8786,   12,   13,  565,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nVectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AiNdaJacT5z",
        "outputId": "7d7bc234-9c88-4e2b-fdd0-249e1c5620b0"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "I highly recommend this law office. Krissy took on my case and took care of it as fast as possible I didn't think I would get my settlement so fast. My accident happened oct. 2016 and received my settlement feb. 2018. She did a great job kept me well updated.      \n",
            "\n",
            "Vectorized version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[   4,  245,  124,   16, 2644,  466,    1,  149,   20,   13,  849,\n",
              "           3,  149,  249,    8]])>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n",
        "bottom_5_words = words_in_vocab[-5:] # least common tokens\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"Top 5 most common words: {top_5_words}\") \n",
        "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnWAntljcXOw",
        "outputId": "b917fe5e-3e67-412a-a0c5-f9c8b74045ed"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 10000\n",
            "Top 5 most common words: ['', '[UNK]', 'the', 'and', 'i']\n",
            "Bottom 5 least common words: ['jpg', 'jonathan', 'jess', 'jenni', 'jasons']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding Layer"
      ],
      "metadata": {
        "id": "x3sbw-fkcfFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "embedding = Embedding(input_dim=max_vocab_length, # set input shape\n",
        "                      output_dim=128, # set size of embedding vector\n",
        "                      embeddings_initializer=\"uniform\", # default, intialize randomly\n",
        "                      input_length=max_length, # how long is each input\n",
        "                      name=\"embedding_1\") \n",
        "\n",
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE1V6JVucbQ2",
        "outputId": "15569bbc-eb69-4786-b817-9f20ae186153"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7f7dd05eac90>"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a random sentence from training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into numerical representation)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCeWsavzcl0E",
        "outputId": "dfb82dcb-818e-4021-e6b9-b533f0330c8c"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "Such a great place to have a good time. Anarbol Martinez totally hooked us up with a bay towards the center on the third floor on a Saturday night where the wait was set to 45 minutes to get a spot on either the third or second floor. Now that's what I call customer service! He's the best!      \n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.02770803, -0.02877747,  0.02347932, ...,  0.03209184,\n",
              "         -0.02208823, -0.00824679],\n",
              "        [-0.03521683, -0.00981399, -0.00284491, ..., -0.04792733,\n",
              "         -0.01664252, -0.03293632],\n",
              "        [ 0.04049121, -0.00741907, -0.00506904, ...,  0.02288493,\n",
              "          0.03335415, -0.04155653],\n",
              "        ...,\n",
              "        [-0.02300658,  0.02515138,  0.00135379, ...,  0.02369482,\n",
              "          0.02020344, -0.04502844],\n",
              "        [-0.0282429 , -0.01332953, -0.03716351, ..., -0.04596538,\n",
              "         -0.02836199, -0.0376353 ],\n",
              "        [-0.01456394,  0.02664156, -0.0070488 , ...,  0.00958163,\n",
              "         -0.01225308,  0.04130488]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out a single token's embedding\n",
        "sample_embed[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zHVNfYuc05a",
        "outputId": "3df68c66-a647-4bcf-e604-593086e78b7c"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              "array([ 0.02770803, -0.02877747,  0.02347932, -0.04396946,  0.03285495,\n",
              "        0.03839954,  0.00806413,  0.02695229,  0.02802075,  0.00113881,\n",
              "        0.0133984 ,  0.04699519,  0.00237359, -0.04237021, -0.02363363,\n",
              "        0.03466617,  0.01312608, -0.0404911 ,  0.03504953, -0.00654498,\n",
              "       -0.02442173,  0.02995959, -0.00733645,  0.00400343, -0.04402372,\n",
              "        0.04039264, -0.01737512,  0.04454163,  0.0497917 , -0.01291456,\n",
              "        0.00721056, -0.00984938, -0.00345488, -0.04044552,  0.03783008,\n",
              "        0.00393597, -0.04253433,  0.0472242 ,  0.03149721, -0.02542652,\n",
              "       -0.02119037,  0.02701832,  0.01857468,  0.0063289 ,  0.0338707 ,\n",
              "       -0.03576756,  0.02940394, -0.01099084, -0.04248435, -0.03011486,\n",
              "        0.03905234, -0.02212126, -0.04244724,  0.04546647,  0.03012883,\n",
              "        0.01994801, -0.00195368,  0.02574405, -0.02841196, -0.02761663,\n",
              "        0.01776842, -0.04653288,  0.02052915,  0.02659552, -0.03576815,\n",
              "       -0.0485217 , -0.04158274,  0.02139703,  0.00950398,  0.04001166,\n",
              "        0.03000149,  0.01525155,  0.04201794,  0.00082841,  0.02770526,\n",
              "       -0.00475073, -0.02846569,  0.04686632,  0.00725591,  0.02068694,\n",
              "        0.02391562, -0.04338196,  0.03770867, -0.00585954,  0.0121314 ,\n",
              "        0.02416915, -0.00680522,  0.01726021,  0.00172053,  0.03131272,\n",
              "       -0.01518128,  0.04301621, -0.00852846, -0.03207254,  0.03916924,\n",
              "       -0.02834374,  0.02469944, -0.00741787,  0.02515011, -0.04155012,\n",
              "        0.0409804 ,  0.00551302,  0.03291373, -0.0315031 ,  0.02242288,\n",
              "       -0.036507  , -0.04812371,  0.03182889, -0.02447282, -0.02248481,\n",
              "        0.03553938, -0.02997375, -0.00410881,  0.00950972,  0.02658284,\n",
              "       -0.02131832,  0.02868625, -0.02145031, -0.00143344,  0.04020883,\n",
              "        0.01338885, -0.0237707 ,  0.01466649, -0.04871545,  0.02380282,\n",
              "        0.03209184, -0.02208823, -0.00824679], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Model : Naive Bayes"
      ],
      "metadata": {
        "id": "Pzegsn8vc9It"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    (\"clf\", MultinomialNB()) # model the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWXVV1MDc46i",
        "outputId": "849176b9-1470-455f-e72a-0d5bad616a7a"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9njwitQCdDx1",
        "outputId": "8101abe8-87f9-405e-883e-f2bafb2c37fe"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model achieves an accuracy of: 80.93%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_stsxa3wdGio",
        "outputId": "80063788-e402-43d4-ad3a-f6e9cc556595"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "  -----\n",
        "  y_true = true labels in the form of a 1D array\n",
        "  y_pred = predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results"
      ],
      "metadata": {
        "id": "3VY3AAnIdIYJ"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N0W_EmZdMMI",
        "outputId": "93d43839-c19e-4237-e87e-cbf991537338"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 80.93420166180103,\n",
              " 'f1': 0.7640829488032853,\n",
              " 'precision': 0.8451710651494836,\n",
              " 'recall': 0.8093420166180103}"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1: A simple dense model"
      ],
      "metadata": {
        "id": "cUYVCF5WdR7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model with the Functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\") # inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs) # turn the input text into numbers\n",
        "x = embedding(x) # create an embedding of the numerized numbers\n",
        "x = layers.GlobalAveragePooling1D()(x) # lower the dimensionality of the embedding (try running the model without this layer and see what happens)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # create the output layer, want binary outputs so use sigmoid activation\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # construct the model"
      ],
      "metadata": {
        "id": "OcBiMlG6dQew"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "DIsHrHLqdeZA"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary of the model\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvuQSIE6dgJD",
        "outputId": "9b2dd0af-8dac-4bf4-d995-2348d83f2051"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_7 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PU-xcLSWdhRp",
        "outputId": "bdbc0096-4251-4578-d9af-4ca4571074e5"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1114/1114 [==============================] - 11s 6ms/step - loss: 0.4306 - accuracy: 0.8008 - val_loss: 0.3668 - val_accuracy: 0.8402\n",
            "Epoch 2/5\n",
            "1114/1114 [==============================] - 6s 5ms/step - loss: 0.3220 - accuracy: 0.8580 - val_loss: 0.3597 - val_accuracy: 0.8420\n",
            "Epoch 3/5\n",
            "1114/1114 [==============================] - 6s 6ms/step - loss: 0.2923 - accuracy: 0.8724 - val_loss: 0.3704 - val_accuracy: 0.8401\n",
            "Epoch 4/5\n",
            "1114/1114 [==============================] - 7s 6ms/step - loss: 0.2754 - accuracy: 0.8794 - val_loss: 0.3795 - val_accuracy: 0.8356\n",
            "Epoch 5/5\n",
            "1114/1114 [==============================] - 7s 6ms/step - loss: 0.2636 - accuracy: 0.8858 - val_loss: 0.3942 - val_accuracy: 0.8298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nTJg6D8dnKm",
        "outputId": "558abdf3-efbd-4ed9-d1da-b1dd05fdf3bc"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "279/279 [==============================] - 1s 5ms/step - loss: 0.3942 - accuracy: 0.8298\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3941967785358429, 0.8297776579856873]"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding.weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoMQ_5Wcd7si",
        "outputId": "ab8c679c-b7d8-4098-a1ad-2944c16d66de"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'embedding_1/embeddings:0' shape=(10000, 128) dtype=float32, numpy=\n",
              " array([[ 0.03871234, -0.03869727,  0.00189553, ...,  0.01281819,\n",
              "          0.02555337, -0.0170142 ],\n",
              "        [ 0.06090167, -0.06761583, -0.01314532, ...,  0.03087384,\n",
              "          0.05670063,  0.005737  ],\n",
              "        [ 0.02220308,  0.02258053,  0.01841767, ..., -0.04997643,\n",
              "         -0.02554815, -0.00498999],\n",
              "        ...,\n",
              "        [-0.11944845,  0.07933617, -0.13057937, ..., -0.06191379,\n",
              "         -0.08575214,  0.11046026],\n",
              "        [ 0.20128457, -0.13633358,  0.16596237, ...,  0.13481452,\n",
              "          0.17523207, -0.15257417],\n",
              "        [ 0.11786641, -0.0924459 ,  0.07385511, ...,  0.1336745 ,\n",
              "          0.06079776, -0.13301806]], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_weights = model_1.get_layer(\"embedding_1\").get_weights()[0]\n",
        "print(embed_weights.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ww07iFEd85z",
        "outputId": "8b4b9991-f81e-422e-b4de-4e40a3e39464"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions (these come back in the form of probabilities)\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs[:10] # only print out the first 10 prediction probabilities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huyVxYtreAkh",
        "outputId": "91d640ed-1fb0-4070-ca8c-288c5a6d5667"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.19590467],\n",
              "       [0.99705184],\n",
              "       [0.85215014],\n",
              "       [0.93634665],\n",
              "       [0.36855054],\n",
              "       [0.02222292],\n",
              "       [0.81128335],\n",
              "       [0.65268654],\n",
              "       [0.20201305],\n",
              "       [0.99990153]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn prediction probabilities into single-dimension tensor of floats\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs)) # squeeze removes single dimensions\n",
        "model_1_preds[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ww6GeD4EeFPx",
        "outputId": "369f634c-20eb-4d05-daf8-aa2d73c33c2b"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_1 metrics\n",
        "model_1_results = calculate_results(y_true=val_labels, \n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbMUwFQneHaO",
        "outputId": "3c0c2657-17c7-4d1d-f8a2-52f00e6a363c"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 82.9777677969908,\n",
              " 'f1': 0.8257380880996882,\n",
              " 'precision': 0.8238985494546599,\n",
              " 'recall': 0.829777677969908}"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Is our simple Keras model better than our baseline model?\n",
        "import numpy as np\n",
        "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4seVpgpeMgm",
        "outputId": "65b6bbce-2e06-41c3-f29d-4f13162b6a9c"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True, False,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a helper function to compare our baseline results to new model results\n",
        "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
        "  for key, value in baseline_results.items():\n",
        "    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")\n",
        "\n",
        "compare_baseline_to_new_results(baseline_results=baseline_results, \n",
        "                                new_model_results=model_1_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-4PlhryeQ6J",
        "outputId": "211440f1-cbd9-4b5c-be53-4b5698e611f3"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 80.93, New accuracy: 82.98, Difference: 2.04\n",
            "Baseline precision: 0.85, New precision: 0.82, Difference: -0.02\n",
            "Baseline recall: 0.81, New recall: 0.83, Difference: 0.02\n",
            "Baseline f1: 0.76, New f1: 0.83, Difference: 0.06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2: LSTM (Recurrent Neural Networks)"
      ],
      "metadata": {
        "id": "GPmC4gmMen5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_2_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_2\")\n",
        "\n",
        "\n",
        "# Create LSTM model\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_2_embedding(x)\n",
        "print(x.shape)\n",
        "# x = layers.LSTM(64, return_sequences=True)(x) # return vector for each word in the Tweet (you can stack RNN cells as long as return_sequences=True)\n",
        "x = layers.LSTM(64)(x) # return vector for whole sequence\n",
        "print(x.shape)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJWWP2kDegAz",
        "outputId": "8b3bc0cf-b4d2-47c3-8e35-917c7ac94152"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 15, 128)\n",
            "(None, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "NOf5QE5weuS1"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zPdz-Hjeyo2",
        "outputId": "af9466b0-9a3c-4ac6-dc37-60327331b4b8"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_7 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5Z5gZcYezmu",
        "outputId": "270a59f0-607b-4600-b5a4-6e9f951ac976"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1114/1114 [==============================] - 14s 8ms/step - loss: 0.3870 - accuracy: 0.8241 - val_loss: 0.3651 - val_accuracy: 0.8410\n",
            "Epoch 2/5\n",
            "1114/1114 [==============================] - 12s 11ms/step - loss: 0.2961 - accuracy: 0.8699 - val_loss: 0.3535 - val_accuracy: 0.8442\n",
            "Epoch 3/5\n",
            "1114/1114 [==============================] - 12s 11ms/step - loss: 0.2438 - accuracy: 0.8930 - val_loss: 0.3857 - val_accuracy: 0.8433\n",
            "Epoch 4/5\n",
            "1114/1114 [==============================] - 9s 8ms/step - loss: 0.1997 - accuracy: 0.9121 - val_loss: 0.4225 - val_accuracy: 0.8322\n",
            "Epoch 5/5\n",
            "1114/1114 [==============================] - 8s 7ms/step - loss: 0.1651 - accuracy: 0.9294 - val_loss: 0.4719 - val_accuracy: 0.8235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the validation dataset\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs.shape, model_2_pred_probs[:10] # view the first 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jhBCE5oe4EG",
        "outputId": "76e46a4b-a511-4fe7-89eb-e63e9b38d3cb"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8906, 1), array([[0.0083376 ],\n",
              "        [0.9984315 ],\n",
              "        [0.11761797],\n",
              "        [0.9828569 ],\n",
              "        [0.54734457],\n",
              "        [0.00214383],\n",
              "        [0.5672105 ],\n",
              "        [0.7659084 ],\n",
              "        [0.3843625 ],\n",
              "        [0.99902236]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Round out predictions and reduce to 1-dimensional array\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR9keSroe8bX",
        "outputId": "2d64de90-5323-4baa-c9ba-369820c91dff"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 0., 1., 1., 0., 1., 1., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate LSTM model results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3NSBrwqe9e-",
        "outputId": "b406dfd6-dfb6-4c5d-a792-c0e1c8c11fd8"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 82.3489782169324,\n",
              " 'f1': 0.8229453321651362,\n",
              " 'precision': 0.8224428631465093,\n",
              " 'recall': 0.823489782169324}"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare model 2 to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_2_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfu0bt4ye_sl",
        "outputId": "470f53eb-f5b9-47b6-8414-22fdd5c819d8"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 80.93, New accuracy: 82.35, Difference: 1.41\n",
            "Baseline precision: 0.85, New precision: 0.82, Difference: -0.02\n",
            "Baseline recall: 0.81, New recall: 0.82, Difference: 0.01\n",
            "Baseline f1: 0.76, New f1: 0.82, Difference: 0.06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 3: Gated Recurrent Unit"
      ],
      "metadata": {
        "id": "O6EoLzOefY4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_3_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_3\")\n",
        "\n",
        "# Build an RNN using the GRU cell\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_3_embedding(x)\n",
        "# x = layers.GRU(64, return_sequences=True) # stacking recurrent cells requires return_sequences=True\n",
        "x = layers.GRU(64)(x) \n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer after GRU cell\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
      ],
      "metadata": {
        "id": "6nnWRo-UfA-j"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile GRU model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "Q7r3KeD7fhSz"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary of the GRU model\n",
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HC0g-eSMfjhT",
        "outputId": "1b90a153-b078-4081-f937-5d79100ce89f"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_7 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5BRdxsVfkdy",
        "outputId": "5c507f3a-0134-4384-a26f-ef3d7d318981"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1114/1114 [==============================] - 11s 7ms/step - loss: 0.3949 - accuracy: 0.8197 - val_loss: 0.3628 - val_accuracy: 0.8427\n",
            "Epoch 2/5\n",
            "1114/1114 [==============================] - 8s 7ms/step - loss: 0.2959 - accuracy: 0.8701 - val_loss: 0.3452 - val_accuracy: 0.8482\n",
            "Epoch 3/5\n",
            "1114/1114 [==============================] - 8s 7ms/step - loss: 0.2369 - accuracy: 0.8992 - val_loss: 0.3754 - val_accuracy: 0.8430\n",
            "Epoch 4/5\n",
            "1114/1114 [==============================] - 11s 10ms/step - loss: 0.1891 - accuracy: 0.9199 - val_loss: 0.4185 - val_accuracy: 0.8310\n",
            "Epoch 5/5\n",
            "1114/1114 [==============================] - 12s 11ms/step - loss: 0.1536 - accuracy: 0.9373 - val_loss: 0.4779 - val_accuracy: 0.8257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the validation data\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs.shape, model_3_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBIwfB9HfnOr",
        "outputId": "ee5fd0f1-558f-487a-e206-578c41e806fb"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8906, 1), array([[0.01607343],\n",
              "        [0.99815685],\n",
              "        [0.8978066 ],\n",
              "        [0.94265634],\n",
              "        [0.65459615],\n",
              "        [0.00169773],\n",
              "        [0.84178245],\n",
              "        [0.43072248],\n",
              "        [0.28488135],\n",
              "        [0.9993197 ]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert prediction probabilities to prediction classes\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vi_KdJriftz3",
        "outputId": "2fbc48fa-40a1-4104-b9ee-50280d2fdf08"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 1., 1., 0., 1., 0., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcuate model_3 results\n",
        "model_3_results = calculate_results(y_true=val_labels, \n",
        "                                    y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weOFo9BOfw4m",
        "outputId": "b275b3ec-b2af-48eb-9511-9760bdc482ea"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 82.57354592409611,\n",
              " 'f1': 0.8252757579479831,\n",
              " 'precision': 0.8248470266963576,\n",
              " 'recall': 0.8257354592409611}"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_3_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7HLxZKffx88",
        "outputId": "7689a046-4672-49a5-fee4-848f776fbd3d"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 80.93, New accuracy: 82.57, Difference: 1.64\n",
            "Baseline precision: 0.85, New precision: 0.82, Difference: -0.02\n",
            "Baseline recall: 0.81, New recall: 0.83, Difference: 0.02\n",
            "Baseline f1: 0.76, New f1: 0.83, Difference: 0.06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 4: Bidirectonal RNN model\n",
        "\n"
      ],
      "metadata": {
        "id": "ysa23wOof6ml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A standard RNN will process a sequence from left to right, where as a bidirectional RNN will process the sequence from left to right and then again from right to left.\n",
        "\n",
        "Intuitively, this can be thought of as if you were reading a sentence for the first time in the normal fashion (left to right) but for some reason it didn't make sense so you traverse back through the words and go back over them again (right to left).\n",
        "\n",
        "In practice, many sequence models often see and improvement in performance when using bidirectional RNN's.\n",
        "\n",
        "However, this improvement in performance often comes at the cost of longer training times and increased model parameters (since the model goes left to right and right to left, the number of trainable parameters doubles).\n",
        "\n",
        "Once again, TensorFlow helps us out by providing the tensorflow.keras.layers.Bidirectional class. We can use the Bidirectional class to wrap our existing RNNs, instantly making them bidirectional."
      ],
      "metadata": {
        "id": "24uLdV3LgxWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_4_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_4\")\n",
        "\n",
        "# Build a Bidirectional RNN in TensorFlow\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_4_embedding(x)\n",
        "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x) # stacking RNN layers requires return_sequences=True\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x) # bidirectional goes both ways so has double the parameters of a regular LSTM layer\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional\")"
      ],
      "metadata": {
        "id": "0ZRWpctAfzh9"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "Jd_mhEhHgFJ8"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary of our bidirectional model\n",
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoyaFSPegKcD",
        "outputId": "f1b650ca-1686-40b3-ca10-859ae2f0a536"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_Bidirectional\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_7 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Notice the increased number of trainable parameters in model_4 (bidirectional LSTM) compared to model_2 (regular LSTM). This is due to the bidirectionality we added to our RNN.\n",
        "\n",
        "Time to fit our bidirectional model and track its performance."
      ],
      "metadata": {
        "id": "bRt0opxqgPTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model (takes longer because of the bidirectional layers)\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8TcmgnWgMFA",
        "outputId": "8e73d196-9366-4694-e97b-cb34d21cd808"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1114/1114 [==============================] - 19s 13ms/step - loss: 0.3846 - accuracy: 0.8243 - val_loss: 0.3493 - val_accuracy: 0.8434\n",
            "Epoch 2/5\n",
            "1114/1114 [==============================] - 13s 12ms/step - loss: 0.2924 - accuracy: 0.8711 - val_loss: 0.3454 - val_accuracy: 0.8474\n",
            "Epoch 3/5\n",
            "1114/1114 [==============================] - 17s 16ms/step - loss: 0.2369 - accuracy: 0.8966 - val_loss: 0.3669 - val_accuracy: 0.8467\n",
            "Epoch 4/5\n",
            "1114/1114 [==============================] - 10s 9ms/step - loss: 0.1848 - accuracy: 0.9204 - val_loss: 0.4284 - val_accuracy: 0.8345\n",
            "Epoch 5/5\n",
            "1114/1114 [==============================] - 10s 9ms/step - loss: 0.1422 - accuracy: 0.9410 - val_loss: 0.5250 - val_accuracy: 0.8230\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with bidirectional RNN on the validation data\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldGfKtSbgTWD",
        "outputId": "7de4807d-2a29-4f04-ea6e-f617c7f81151"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.7836123e-04],\n",
              "       [9.9997580e-01],\n",
              "       [6.3112094e-03],\n",
              "       [9.1654748e-01],\n",
              "       [5.8983284e-01],\n",
              "       [2.9171905e-03],\n",
              "       [9.8176378e-01],\n",
              "       [8.7566227e-01],\n",
              "       [1.2875442e-01],\n",
              "       [9.9954671e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fi_SoUpSgWB9",
        "outputId": "adca7342-ce27-4914-95d1-183da0e5d0ff"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 0., 1., 1., 0., 1., 1., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate bidirectional RNN model results\n",
        "model_4_results = calculate_results(val_labels, model_4_preds)\n",
        "model_4_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4aMMZjpgXHt",
        "outputId": "19b9b439-2607-4154-8731-cb912a808184"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 82.30406467549966,\n",
              " 'f1': 0.8236438126450155,\n",
              " 'precision': 0.8243008916729723,\n",
              " 'recall': 0.8230406467549967}"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check to see how the bidirectional model performs against the baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_4_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L460USdAgYzD",
        "outputId": "5d545b72-8d1e-4eb7-f85b-4d730d1c5c2e"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 80.93, New accuracy: 82.30, Difference: 1.37\n",
            "Baseline precision: 0.85, New precision: 0.82, Difference: -0.02\n",
            "Baseline recall: 0.81, New recall: 0.82, Difference: 0.01\n",
            "Baseline f1: 0.76, New f1: 0.82, Difference: 0.06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Networks for Text"
      ],
      "metadata": {
        "id": "vKqOk79jgbQR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You might've used convolutional neural networks (CNNs) for images before but they can also be used for sequences.\n",
        "\n",
        "The main difference between using CNNs for images and sequences is the shape of the data. Images come in 2-dimensions (height x width) where as sequences are often 1-dimensional (a string of text).\n",
        "\n",
        "So to use CNNs with sequences, we use a 1-dimensional convolution instead of a 2-dimensional convolution.\n",
        "\n",
        "A typical CNN architecture for sequences will look like the following:\n",
        "\n",
        "Inputs (text) -> Tokenization -> Embedding -> Layers -> Outputs (class probabilities)"
      ],
      "metadata": {
        "id": "3O1rR4c2g0Qo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 5: Conv1D"
      ],
      "metadata": {
        "id": "IqnWvgCjg5e8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we build a full 1-dimensional CNN model, let's see a 1-dimensional convolutional layer (also called a temporal convolution) in action.\n",
        "\n",
        "We'll first create an embedding of a sample of text and experiment passing it through a Conv1D() layer and GlobalMaxPool1D() layer."
      ],
      "metadata": {
        "id": "dm-d66rog-hX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out the embedding, 1D convolutional and max pooling\n",
        "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"])) # turn target sentence into embedding\n",
        "conv_1d = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\") # convolve over target sequence 5 words at a time\n",
        "conv_1d_output = conv_1d(embedding_test) # pass embedding through 1D convolutional layer\n",
        "max_pool = layers.GlobalMaxPool1D() \n",
        "max_pool_output = max_pool(conv_1d_output) # get the most important features\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVQLD-zIgafS",
        "outputId": "98c90331-55ec-4cdc-b9d8-fc2dedfb95e1"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the output shapes of each layer.\n",
        "\n",
        "The embedding has an output shape dimension of the parameters we set it to (input_length=15 and output_dim=128).\n",
        "\n",
        "The 1-dimensional convolutional layer has an output which has been compressed inline with its parameters. And the same goes for the max pooling layer output.\n",
        "\n",
        "Our text starts out as a string but gets converted to a feature vector of length 64 through various transformation steps (from tokenization to embedding to 1-dimensional convolution to max pool).\n",
        "\n",
        "Let's take a peak at what each of these transformations looks like."
      ],
      "metadata": {
        "id": "ysxP2osqhC6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# See the outputs of each layer\n",
        "embedding_test[:1], conv_1d_output[:1], max_pool_output[:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6YycDyPhA0T",
        "outputId": "b2f15135-c8e4-4865-973e-6660c774171a"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              " array([[[ 0.01599608, -0.03830674,  0.01893974, ...,  0.02351819,\n",
              "           0.04738515, -0.02535202],\n",
              "         [-0.03182955,  0.02554603,  0.01298493, ...,  0.05565028,\n",
              "          -0.01292515,  0.05094353],\n",
              "         [-0.01704365, -0.04015286,  0.015127  , ..., -0.02315823,\n",
              "           0.00169129, -0.05018114],\n",
              "         ...,\n",
              "         [ 0.03871234, -0.03869727,  0.00189553, ...,  0.01281819,\n",
              "           0.02555337, -0.0170142 ],\n",
              "         [ 0.03871234, -0.03869727,  0.00189553, ...,  0.01281819,\n",
              "           0.02555337, -0.0170142 ],\n",
              "         [ 0.03871234, -0.03869727,  0.00189553, ...,  0.01281819,\n",
              "           0.02555337, -0.0170142 ]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 11, 32), dtype=float32, numpy=\n",
              " array([[[0.0215404 , 0.11294822, 0.04790434, 0.01488059, 0.        ,\n",
              "          0.        , 0.        , 0.02871225, 0.0299211 , 0.05193426,\n",
              "          0.        , 0.03357544, 0.04766515, 0.        , 0.        ,\n",
              "          0.        , 0.        , 0.        , 0.        , 0.0839726 ,\n",
              "          0.        , 0.        , 0.        , 0.06273851, 0.0254306 ,\n",
              "          0.0033744 , 0.02318742, 0.        , 0.07822789, 0.06152052,\n",
              "          0.        , 0.11691706],\n",
              "         [0.01838177, 0.        , 0.        , 0.        , 0.04158354,\n",
              "          0.        , 0.        , 0.04066914, 0.01021848, 0.04732817,\n",
              "          0.        , 0.08586571, 0.13417837, 0.03168926, 0.        ,\n",
              "          0.        , 0.        , 0.06082279, 0.        , 0.        ,\n",
              "          0.        , 0.        , 0.01797525, 0.        , 0.01837208,\n",
              "          0.        , 0.        , 0.0215375 , 0.08164464, 0.12031692,\n",
              "          0.        , 0.13021877],\n",
              "         [0.        , 0.        , 0.        , 0.        , 0.0194055 ,\n",
              "          0.        , 0.01694143, 0.03418195, 0.02066832, 0.01023256,\n",
              "          0.        , 0.0613047 , 0.        , 0.        , 0.01833981,\n",
              "          0.05703743, 0.04830477, 0.01183987, 0.        , 0.        ,\n",
              "          0.00628901, 0.        , 0.        , 0.        , 0.01777159,\n",
              "          0.        , 0.        , 0.04844268, 0.05842641, 0.17486843,\n",
              "          0.        , 0.        ],\n",
              "         [0.01289056, 0.        , 0.06082894, 0.        , 0.        ,\n",
              "          0.        , 0.        , 0.00670488, 0.        , 0.0360254 ,\n",
              "          0.        , 0.15065345, 0.07431561, 0.        , 0.06408338,\n",
              "          0.        , 0.04514952, 0.09320292, 0.        , 0.0232414 ,\n",
              "          0.        , 0.        , 0.        , 0.14881688, 0.07812391,\n",
              "          0.        , 0.        , 0.06798363, 0.0495598 , 0.02438482,\n",
              "          0.13387066, 0.        ],\n",
              "         [0.02344864, 0.        , 0.00537268, 0.        , 0.05033056,\n",
              "          0.        , 0.        , 0.03686161, 0.        , 0.05822132,\n",
              "          0.        , 0.08177166, 0.        , 0.        , 0.03860183,\n",
              "          0.0060695 , 0.04036211, 0.02262516, 0.        , 0.        ,\n",
              "          0.        , 0.        , 0.        , 0.01580718, 0.04139379,\n",
              "          0.        , 0.        , 0.01979626, 0.01057623, 0.09169042,\n",
              "          0.04952797, 0.        ],\n",
              "         [0.04819616, 0.        , 0.        , 0.        , 0.04016491,\n",
              "          0.        , 0.        , 0.04635887, 0.        , 0.03623388,\n",
              "          0.        , 0.10391721, 0.        , 0.01953293, 0.        ,\n",
              "          0.        , 0.03881201, 0.00128636, 0.        , 0.00300921,\n",
              "          0.        , 0.        , 0.        , 0.02205574, 0.09047298,\n",
              "          0.00119131, 0.        , 0.02301335, 0.03582966, 0.07922568,\n",
              "          0.0240813 , 0.        ],\n",
              "         [0.04819616, 0.        , 0.        , 0.        , 0.04016491,\n",
              "          0.        , 0.        , 0.04635888, 0.        , 0.03623387,\n",
              "          0.        , 0.10391722, 0.        , 0.01953294, 0.        ,\n",
              "          0.        , 0.03881201, 0.00128635, 0.        , 0.0030092 ,\n",
              "          0.        , 0.        , 0.        , 0.02205573, 0.09047298,\n",
              "          0.00119132, 0.        , 0.02301335, 0.03582965, 0.07922567,\n",
              "          0.02408129, 0.        ],\n",
              "         [0.04819616, 0.        , 0.        , 0.        , 0.04016491,\n",
              "          0.        , 0.        , 0.04635887, 0.        , 0.03623387,\n",
              "          0.        , 0.10391721, 0.        , 0.01953293, 0.        ,\n",
              "          0.        , 0.03881202, 0.00128634, 0.        , 0.0030092 ,\n",
              "          0.        , 0.        , 0.        , 0.02205573, 0.09047298,\n",
              "          0.00119131, 0.        , 0.02301335, 0.03582965, 0.07922567,\n",
              "          0.02408131, 0.        ],\n",
              "         [0.04819617, 0.        , 0.        , 0.        , 0.04016492,\n",
              "          0.        , 0.        , 0.04635888, 0.        , 0.03623387,\n",
              "          0.        , 0.10391723, 0.        , 0.01953294, 0.        ,\n",
              "          0.        , 0.038812  , 0.00128635, 0.        , 0.00300921,\n",
              "          0.        , 0.        , 0.        , 0.02205573, 0.09047298,\n",
              "          0.00119132, 0.        , 0.02301335, 0.03582966, 0.07922567,\n",
              "          0.02408129, 0.        ],\n",
              "         [0.04819616, 0.        , 0.        , 0.        , 0.04016493,\n",
              "          0.        , 0.        , 0.04635887, 0.        , 0.03623387,\n",
              "          0.        , 0.10391721, 0.        , 0.01953295, 0.        ,\n",
              "          0.        , 0.03881201, 0.00128635, 0.        , 0.0030092 ,\n",
              "          0.        , 0.        , 0.        , 0.02205573, 0.09047299,\n",
              "          0.00119132, 0.        , 0.02301335, 0.03582965, 0.07922569,\n",
              "          0.02408129, 0.        ],\n",
              "         [0.04819617, 0.        , 0.        , 0.        , 0.04016492,\n",
              "          0.        , 0.        , 0.04635888, 0.        , 0.03623386,\n",
              "          0.        , 0.10391721, 0.        , 0.01953294, 0.        ,\n",
              "          0.        , 0.03881201, 0.00128636, 0.        , 0.00300919,\n",
              "          0.        , 0.        , 0.        , 0.02205572, 0.09047298,\n",
              "          0.00119132, 0.        , 0.02301336, 0.03582965, 0.07922568,\n",
              "          0.02408129, 0.        ]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
              " array([[0.04819617, 0.11294822, 0.06082894, 0.01488059, 0.05033056,\n",
              "         0.        , 0.01694143, 0.04635888, 0.0299211 , 0.05822132,\n",
              "         0.        , 0.15065345, 0.13417837, 0.03168926, 0.06408338,\n",
              "         0.05703743, 0.04830477, 0.09320292, 0.        , 0.0839726 ,\n",
              "         0.00628901, 0.        , 0.01797525, 0.14881688, 0.09047299,\n",
              "         0.0033744 , 0.02318742, 0.06798363, 0.08164464, 0.17486843,\n",
              "         0.13387066, 0.13021877]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_5_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_5\")\n",
        "\n",
        "# Create 1-dimensional convolutional layer to model sequences\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_5_embedding(x)\n",
        "x = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n",
        "\n",
        "# Compile Conv1D model\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get a summary of our 1D convolution model\n",
        "model_5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrEqjZz-hFfd",
        "outputId": "23b94704-08d2-4dd9-8f07-4f539f25e6ca"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_7 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 11, 32)            20512     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 32)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,300,545\n",
            "Trainable params: 1,300,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyoY9KqzhISz",
        "outputId": "d75faddb-1abb-4558-bbd9-42b2cc33cf59"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1114/1114 [==============================] - 11s 8ms/step - loss: 0.4037 - accuracy: 0.8134 - val_loss: 0.3607 - val_accuracy: 0.8376\n",
            "Epoch 2/5\n",
            "1114/1114 [==============================] - 13s 12ms/step - loss: 0.2850 - accuracy: 0.8786 - val_loss: 0.3680 - val_accuracy: 0.8382\n",
            "Epoch 3/5\n",
            "1114/1114 [==============================] - 7s 6ms/step - loss: 0.2008 - accuracy: 0.9208 - val_loss: 0.4152 - val_accuracy: 0.8338\n",
            "Epoch 4/5\n",
            "1114/1114 [==============================] - 7s 6ms/step - loss: 0.1256 - accuracy: 0.9544 - val_loss: 0.4838 - val_accuracy: 0.8285\n",
            "Epoch 5/5\n",
            "1114/1114 [==============================] - 10s 9ms/step - loss: 0.0682 - accuracy: 0.9786 - val_loss: 0.5803 - val_accuracy: 0.8230\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with model_5\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWZw9xm8hNfz",
        "outputId": "d2d3bec9-2e7d-412b-8169-ece6eb9996aa"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.2827311e-02],\n",
              "       [9.9944323e-01],\n",
              "       [7.5288302e-01],\n",
              "       [9.9980992e-01],\n",
              "       [5.1950112e-02],\n",
              "       [4.9207538e-06],\n",
              "       [9.8747545e-01],\n",
              "       [9.9685943e-01],\n",
              "       [2.8002808e-02],\n",
              "       [9.9999988e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model_5 prediction probabilities to labels\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOP7HwCehPHz",
        "outputId": "4713fc43-cfdc-40ad-c6e6-5e8bb948b801"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 1., 0., 0., 1., 1., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_5 evaluation metrics \n",
        "model_5_results = calculate_results(y_true=val_labels, \n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCDqtO_DhQUV",
        "outputId": "81c48b30-9783-4274-f3db-ac3ca807fcf1"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 82.30406467549966,\n",
              " 'f1': 0.8208673618194506,\n",
              " 'precision': 0.8193165950649353,\n",
              " 'recall': 0.8230406467549967}"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Pretrained Embeddings (transfer learning for NLP)"
      ],
      "metadata": {
        "id": "uAngacZmhXCH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For all of the previous deep learning models we've built and trained, we've created and used our own embeddings from scratch each time.\n",
        "\n",
        "However, a common practice is to leverage pretrained embeddings through transfer learning. This is one of the main benefits of using deep models: being able to take what one (often larger) model has learned (often on a large amount of data) and adjust it for our own use case.\n",
        "\n",
        "For our next model, instead of using our own embedding layer, we're going to replace it with a pretrained embedding layer.\n",
        "\n",
        "More specifically, we're going to be using the Universal Sentence Encoder from TensorFlow Hub (a great resource containing a plethora of pretrained model resources for a variety of tasks).\n",
        "\n",
        "🔑 Note: There are many different pretrained text embedding options on TensorFlow Hub, however, some require different levels of text preprocessing than others. Best to experiment with a few and see which best suits your use case."
      ],
      "metadata": {
        "id": "9Uk0V5ZlhYK0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 6: TensorFlow Hub Pretrained Sentence Encoder"
      ],
      "metadata": {
        "id": "txe-QliphdIE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main difference between the embedding layer we created and the Universal Sentence Encoder is that rather than create a word-level embedding, the Universal Sentence Encoder, as you might've guessed, creates a whole sentence-level embedding.\n",
        "\n",
        "Our embedding layer also outputs an a 128 dimensional vector for each word, where as, the Universal Sentence Encoder outputs a 512 dimensional vector for each sentence.\n",
        "\n",
        "The feature extractor model we're building through the eyes of an encoder/decoder model.\n",
        "\n",
        "🔑 Note: An encoder is the name for a model which converts raw data such as text into a numerical representation (feature vector), a decoder converts the numerical representation to a desired output.\n",
        "\n",
        "As usual, this is best demonstrated with an example.\n",
        "\n",
        "We can load in a TensorFlow Hub module using the hub.load() method and passing it the target URL of the module we'd like to use, in our case, it's \"https://tfhub.dev/google/universal-sentence-encoder/4\".\n",
        "\n",
        "Let's load the Universal Sentence Encoder model and test it on a couple of sentences."
      ],
      "metadata": {
        "id": "cCiDD-J7hqjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of pretrained embedding with universal sentence encoder - https://tfhub.dev/google/universal-sentence-encoder/4\n",
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\") # load Universal Sentence Encoder\n",
        "embed_samples = embed([sample_sentence,\n",
        "                      \"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
        "\n",
        "print(embed_samples[0][:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXr4j-qbhR1X",
        "outputId": "0865c587-1d9b-4a62-9312-bf6edc13bb1b"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[-0.01157028  0.0248591   0.02878048 -0.012715    0.03971538  0.0882776\n",
            "  0.02680984  0.05589836 -0.0106873  -0.00597291  0.00639323 -0.01819518\n",
            "  0.00030813  0.09105888  0.05874644 -0.03180628  0.01512474 -0.05162929\n",
            "  0.00991367 -0.06865347 -0.04209306  0.02678981  0.03011006  0.00321069\n",
            " -0.00337973 -0.04787357  0.0226672  -0.00985925 -0.04063613 -0.01292092\n",
            " -0.04666384  0.05630299 -0.03949255  0.00517686  0.02495829 -0.0701444\n",
            "  0.02871508  0.04947684 -0.00633979 -0.08960192  0.02807118 -0.00808364\n",
            " -0.01360602  0.0599865  -0.10361787 -0.05195374  0.00232954 -0.02332531\n",
            " -0.03758105  0.03327728], shape=(50,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Each sentence has been encoded into a 512 dimension vector\n",
        "embed_samples[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvOlWrarhfho",
        "outputId": "52edbf4c-52c8-427c-e944-440540d524c6"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512])"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can use this encoding layer in place of our text_vectorizer and embedding layer\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[], # shape of inputs coming to our model \n",
        "                                        dtype=tf.string, # data type of inputs coming to the USE layer\n",
        "                                        trainable=False, # keep the pretrained weights (we'll create a feature extractor)\n",
        "                                        name=\"USE\") "
      ],
      "metadata": {
        "id": "wSyYCXPFhw1A"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model using the Sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "  sentence_encoder_layer, # take in sentences and then encode them into an embedding\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(1, activation=\"sigmoid\")\n",
        "], name=\"model_6_USE\")\n",
        "\n",
        "# Compile model\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model_6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiCf6snIhyTy",
        "outputId": "47e5e028-0b0f-409a-d06b-6e98a7ab9ae3"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a classifier on top of pretrained embeddings\n",
        "model_6_history = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_JuiasSh0Vf",
        "outputId": "9178d67e-254d-46bf-a589-6bb5aa827a79"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1114/1114 [==============================] - 46s 38ms/step - loss: 0.1887 - accuracy: 0.9263 - val_loss: 0.1571 - val_accuracy: 0.9379\n",
            "Epoch 2/5\n",
            "1114/1114 [==============================] - 34s 31ms/step - loss: 0.1448 - accuracy: 0.9422 - val_loss: 0.1561 - val_accuracy: 0.9386\n",
            "Epoch 3/5\n",
            "1114/1114 [==============================] - 35s 32ms/step - loss: 0.1416 - accuracy: 0.9432 - val_loss: 0.1622 - val_accuracy: 0.9370\n",
            "Epoch 4/5\n",
            "1114/1114 [==============================] - 37s 33ms/step - loss: 0.1385 - accuracy: 0.9450 - val_loss: 0.1537 - val_accuracy: 0.9400\n",
            "Epoch 5/5\n",
            "1114/1114 [==============================] - 36s 32ms/step - loss: 0.1350 - accuracy: 0.9464 - val_loss: 0.1495 - val_accuracy: 0.9411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with USE TF Hub model\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPO89Cd9h7G4",
        "outputId": "8af1b986-21ab-44dc-d382-4fd2ced63627"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9851863 ],\n",
              "       [0.99902916],\n",
              "       [0.05330412],\n",
              "       [0.9998419 ],\n",
              "       [0.05279095],\n",
              "       [0.01278452],\n",
              "       [0.4422611 ],\n",
              "       [0.00419876],\n",
              "       [0.9992336 ],\n",
              "       [0.9933948 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdV9C6y3h8ul",
        "outputId": "ed588ffb-98aa-4c58-abb4-fe5865bce907"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 0., 1., 0., 0., 0., 0., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model 6 performance metrics\n",
        "model_6_results = calculate_results(val_labels, model_6_preds)\n",
        "model_6_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12kXLUCph942",
        "outputId": "58e11837-e6f0-4a7c-e501-d5f2eef3d88d"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 94.10509768695262,\n",
              " 'f1': 0.9411313779122601,\n",
              " 'precision': 0.9412225474565296,\n",
              " 'recall': 0.9410509768695262}"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare TF Hub model to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_6_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQ1kFG3Mh_s9",
        "outputId": "c9aec6b2-6522-41e0-cfd1-5035c533a8dd"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 80.93, New accuracy: 94.11, Difference: 13.17\n",
            "Baseline precision: 0.85, New precision: 0.94, Difference: 0.10\n",
            "Baseline recall: 0.81, New recall: 0.94, Difference: 0.13\n",
            "Baseline f1: 0.76, New f1: 0.94, Difference: 0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 7: TensorFlow Hub Pretrained Sentence Encoder 10% of the training data"
      ],
      "metadata": {
        "id": "ccU6u_00iss2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences_90_percent, train_sentences_10_percent, train_labels_90_percent, train_labels_10_percent = train_test_split(np.array(train_sentences),\n",
        "                                                                                                                            train_labels,\n",
        "                                                                                                                            test_size=0.1,\n",
        "                                                                                                                            random_state=42)"
      ],
      "metadata": {
        "id": "JASVJGHNiBKg"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check length of 10 percent datasets\n",
        "print(f\"Total training examples: {len(train_sentences)}\")\n",
        "print(f\"Length of 10% training examples: {len(train_sentences_10_percent)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8LihigSi8SH",
        "outputId": "6c4dface-b5b3-410d-bd51-1479921e601a"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training examples: 35624\n",
            "Length of 10% training examples: 3563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of targets in our subset of data \n",
        "# (this should be close to the distribution of labels in the original train_labels)\n",
        "pd.Series(train_labels_10_percent).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fiQ-_G8i9yY",
        "outputId": "0ece3b51-d7ef-4140-ed9b-c415021965f4"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    2647\n",
              "0     916\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone model_6 but reset weights\n",
        "model_7 = tf.keras.models.clone_model(model_6)\n",
        "\n",
        "# Compile model\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get a summary (will be same as model_6)\n",
        "model_7.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXReS2Y3i_Of",
        "outputId": "f31bca19-2f3a-48cd-c529-3bddddc11574"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fit the model to 10% of the training data\n",
        "model_7_history = model_7.fit(x=train_sentences_10_percent,\n",
        "                              y=train_labels_10_percent,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7YlBzTBjFAr",
        "outputId": "020ddcfb-e2ed-4669-9e3d-52771a9b46e3"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "112/112 [==============================] - 14s 93ms/step - loss: 0.4280 - accuracy: 0.8075 - val_loss: 0.2743 - val_accuracy: 0.9096\n",
            "Epoch 2/5\n",
            "112/112 [==============================] - 14s 124ms/step - loss: 0.2225 - accuracy: 0.9214 - val_loss: 0.1957 - val_accuracy: 0.9256\n",
            "Epoch 3/5\n",
            "112/112 [==============================] - 9s 82ms/step - loss: 0.1771 - accuracy: 0.9310 - val_loss: 0.1768 - val_accuracy: 0.9287\n",
            "Epoch 4/5\n",
            "112/112 [==============================] - 14s 127ms/step - loss: 0.1605 - accuracy: 0.9380 - val_loss: 0.1716 - val_accuracy: 0.9302\n",
            "Epoch 5/5\n",
            "112/112 [==============================] - 11s 96ms/step - loss: 0.1527 - accuracy: 0.9377 - val_loss: 0.1683 - val_accuracy: 0.9321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with the model trained on 10% of the data\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVtJ0kMVjIE-",
        "outputId": "56ddd6fa-51af-40f4-dc35-4e9b6d2c71c4"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9781516 ],\n",
              "       [0.9982395 ],\n",
              "       [0.21154617],\n",
              "       [0.9997949 ],\n",
              "       [0.12941796],\n",
              "       [0.01107778],\n",
              "       [0.32089096],\n",
              "       [0.01436467],\n",
              "       [0.9959403 ],\n",
              "       [0.9913852 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Npz5NE-ajMVM",
        "outputId": "3821e306-b7b8-46a6-85e4-adf0a65ea61b"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 0., 1., 0., 0., 0., 0., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model results\n",
        "model_7_results = calculate_results(val_labels, model_7_preds)\n",
        "model_7_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nB7AJ5WEjNP0",
        "outputId": "5be60baf-d621-4795-a45e-7494b42f1fcd"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 93.20682685829777,\n",
              " 'f1': 0.9312835604405011,\n",
              " 'precision': 0.9311992435306915,\n",
              " 'recall': 0.9320682685829778}"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_7_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsO4Gv6ujOaf",
        "outputId": "681b41bd-29be-430c-d69a-9a810baf1456"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 80.93, New accuracy: 93.21, Difference: 12.27\n",
            "Baseline precision: 0.85, New precision: 0.93, Difference: 0.09\n",
            "Baseline recall: 0.81, New recall: 0.93, Difference: 0.12\n",
            "Baseline f1: 0.76, New f1: 0.93, Difference: 0.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparing the performance of each of our models"
      ],
      "metadata": {
        "id": "BQXYZlEhjWO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine model results into a DataFrame\n",
        "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
        "                                  \"simple_dense\": model_1_results,\n",
        "                                  \"lstm\": model_2_results,\n",
        "                                  \"gru\": model_3_results,\n",
        "                                  \"bidirectional\": model_4_results,\n",
        "                                  \"conv1d\": model_5_results,\n",
        "                                  \"tf_hub_sentence_encoder\": model_6_results,\n",
        "                                  \"tf_hub_10_percent_data\": model_7_results})\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "8qDY9AEVjSZG",
        "outputId": "f6e4c69e-5ca9-4a8e-89af-5b48e489bbcb"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          accuracy  precision    recall        f1\n",
              "baseline                 80.934202   0.845171  0.809342  0.764083\n",
              "simple_dense             82.977768   0.823899  0.829778  0.825738\n",
              "lstm                     82.348978   0.822443  0.823490  0.822945\n",
              "gru                      82.573546   0.824847  0.825735  0.825276\n",
              "bidirectional            82.304065   0.824301  0.823041  0.823644\n",
              "conv1d                   82.304065   0.819317  0.823041  0.820867\n",
              "tf_hub_sentence_encoder  94.105098   0.941223  0.941051  0.941131\n",
              "tf_hub_10_percent_data   93.206827   0.931199  0.932068  0.931284"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a1d15b86-c7a4-436e-a774-c659cad28f28\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>80.934202</td>\n",
              "      <td>0.845171</td>\n",
              "      <td>0.809342</td>\n",
              "      <td>0.764083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>simple_dense</th>\n",
              "      <td>82.977768</td>\n",
              "      <td>0.823899</td>\n",
              "      <td>0.829778</td>\n",
              "      <td>0.825738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lstm</th>\n",
              "      <td>82.348978</td>\n",
              "      <td>0.822443</td>\n",
              "      <td>0.823490</td>\n",
              "      <td>0.822945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gru</th>\n",
              "      <td>82.573546</td>\n",
              "      <td>0.824847</td>\n",
              "      <td>0.825735</td>\n",
              "      <td>0.825276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bidirectional</th>\n",
              "      <td>82.304065</td>\n",
              "      <td>0.824301</td>\n",
              "      <td>0.823041</td>\n",
              "      <td>0.823644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conv1d</th>\n",
              "      <td>82.304065</td>\n",
              "      <td>0.819317</td>\n",
              "      <td>0.823041</td>\n",
              "      <td>0.820867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_sentence_encoder</th>\n",
              "      <td>94.105098</td>\n",
              "      <td>0.941223</td>\n",
              "      <td>0.941051</td>\n",
              "      <td>0.941131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_10_percent_data</th>\n",
              "      <td>93.206827</td>\n",
              "      <td>0.931199</td>\n",
              "      <td>0.932068</td>\n",
              "      <td>0.931284</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1d15b86-c7a4-436e-a774-c659cad28f28')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a1d15b86-c7a4-436e-a774-c659cad28f28 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a1d15b86-c7a4-436e-a774-c659cad28f28');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce the accuracy to same scale as other metrics\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"
      ],
      "metadata": {
        "id": "1sDdp7oXjZ-P"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot and compare all of the model results\n",
        "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "WDXHWs9Njch2",
        "outputId": "ffed234a-57c9-45db-d8c0-fccc5eca01f6"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort model results by f1-score\n",
        "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "yBFRpuCLjfS3",
        "outputId": "b0acb75f-64fe-4b05-b14e-f8f148e23c13"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble Model : Combining our models (model stacking)"
      ],
      "metadata": {
        "id": "FY0ZIMNVjmQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get mean pred probs for 3 models\n",
        "baseline_pred_probs = np.max(model_0.predict_proba(val_sentences), axis=1) # get the prediction probabilities from baseline model\n",
        "combined_pred_probs = baseline_pred_probs + tf.squeeze(model_2_pred_probs, axis=1) + tf.squeeze(model_6_pred_probs)\n",
        "combined_preds = tf.round(combined_pred_probs/3) # average and round the prediction probabilities to get prediction classes\n",
        "combined_preds[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YH-u5tXNjjcV",
        "outputId": "0e26c775-8e2b-413f-c64b-1c639a025cd1"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
              "       1., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate results from averaging the prediction probabilities\n",
        "ensemble_results = calculate_results(val_labels, combined_preds)\n",
        "ensemble_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B08d58ZIjtrn",
        "outputId": "717e46d9-d6da-4acd-9afe-83404218ff34"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 90.8713227037952,\n",
              " 'f1': 0.9035534154355931,\n",
              " 'precision': 0.9114993301264417,\n",
              " 'recall': 0.908713227037952}"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add our combined model's results to the results DataFrame\n",
        "all_model_results.loc[\"ensemble_results\"] = ensemble_results"
      ],
      "metadata": {
        "id": "pksrD0N5juuy"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the accuracy to the same scale as the rest of the results\n",
        "all_model_results.loc[\"ensemble_results\"][\"accuracy\"] = all_model_results.loc[\"ensemble_results\"][\"accuracy\"]/100"
      ],
      "metadata": {
        "id": "RnPXj6jGjv3H"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_model_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "8gExPrOdjyP4",
        "outputId": "1caa764f-985e-44c5-d58b-0016916848c0"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         accuracy  precision    recall        f1\n",
              "baseline                 0.809342   0.845171  0.809342  0.764083\n",
              "simple_dense             0.829778   0.823899  0.829778  0.825738\n",
              "lstm                     0.823490   0.822443  0.823490  0.822945\n",
              "gru                      0.825735   0.824847  0.825735  0.825276\n",
              "bidirectional            0.823041   0.824301  0.823041  0.823644\n",
              "conv1d                   0.823041   0.819317  0.823041  0.820867\n",
              "tf_hub_sentence_encoder  0.941051   0.941223  0.941051  0.941131\n",
              "tf_hub_10_percent_data   0.932068   0.931199  0.932068  0.931284\n",
              "ensemble_results         0.009087   0.911499  0.908713  0.903553"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3963cf09-259d-4159-aced-8ed7227e6ad4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>0.809342</td>\n",
              "      <td>0.845171</td>\n",
              "      <td>0.809342</td>\n",
              "      <td>0.764083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>simple_dense</th>\n",
              "      <td>0.829778</td>\n",
              "      <td>0.823899</td>\n",
              "      <td>0.829778</td>\n",
              "      <td>0.825738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lstm</th>\n",
              "      <td>0.823490</td>\n",
              "      <td>0.822443</td>\n",
              "      <td>0.823490</td>\n",
              "      <td>0.822945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gru</th>\n",
              "      <td>0.825735</td>\n",
              "      <td>0.824847</td>\n",
              "      <td>0.825735</td>\n",
              "      <td>0.825276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bidirectional</th>\n",
              "      <td>0.823041</td>\n",
              "      <td>0.824301</td>\n",
              "      <td>0.823041</td>\n",
              "      <td>0.823644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conv1d</th>\n",
              "      <td>0.823041</td>\n",
              "      <td>0.819317</td>\n",
              "      <td>0.823041</td>\n",
              "      <td>0.820867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_sentence_encoder</th>\n",
              "      <td>0.941051</td>\n",
              "      <td>0.941223</td>\n",
              "      <td>0.941051</td>\n",
              "      <td>0.941131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_10_percent_data</th>\n",
              "      <td>0.932068</td>\n",
              "      <td>0.931199</td>\n",
              "      <td>0.932068</td>\n",
              "      <td>0.931284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ensemble_results</th>\n",
              "      <td>0.009087</td>\n",
              "      <td>0.911499</td>\n",
              "      <td>0.908713</td>\n",
              "      <td>0.903553</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3963cf09-259d-4159-aced-8ed7227e6ad4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3963cf09-259d-4159-aced-8ed7227e6ad4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3963cf09-259d-4159-aced-8ed7227e6ad4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving and loading a trained model"
      ],
      "metadata": {
        "id": "9I1tfKTBj9vC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although training time didn't take very long, it's good practice to save your trained models to avoid having to retrain them.\n",
        "\n",
        "Saving your models also enables you to export them for use elsewhere outside of your notebooks, such as in a web application.\n",
        "\n",
        "There are two main ways of saving a model in TensorFlow:\n",
        "\n",
        "The HDF5 format.\n",
        "The SavedModel format (default).\n",
        "Let's take a look at both.\n",
        "\n"
      ],
      "metadata": {
        "id": "wKaH6JsUkAkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save TF Hub Sentence Encoder model to HDF5 format\n",
        "model_6.save(\"model_6.h5\")"
      ],
      "metadata": {
        "id": "jHuVZPQKj0D-"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model with custom Hub Layer (required with HDF5 format)\n",
        "loaded_model_6 = tf.keras.models.load_model(\"model_6.h5\", \n",
        "                                            custom_objects={\"KerasLayer\": hub.KerasLayer})"
      ],
      "metadata": {
        "id": "o9App7uZkCqj"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How does our loaded model perform?\n",
        "loaded_model_6.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6wvpg1ZkEmZ",
        "outputId": "f5d613a0-85f5-4524-b21e-7dcf62b5e685"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "279/279 [==============================] - 10s 37ms/step - loss: 0.1495 - accuracy: 0.9411\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1495366096496582, 0.9410510063171387]"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save TF Hub Sentence Encoder model to SavedModel format (default)\n",
        "model_6.save(\"model_6_SavedModel_format\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usTccb6skGEW",
        "outputId": "3320f473-ea4f-49d7-e447-ae4bbf859595"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load TF Hub Sentence Encoder SavedModel\n",
        "loaded_model_6_SavedModel = tf.keras.models.load_model(\"model_6_SavedModel_format\")"
      ],
      "metadata": {
        "id": "NSscnw_JkJgq"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate loaded SavedModel format\n",
        "loaded_model_6_SavedModel.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPIrUwc-kMSr",
        "outputId": "03a38825-8532-4cd3-de64-405d4f90d493"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "279/279 [==============================] - 9s 30ms/step - loss: 0.1495 - accuracy: 0.9411\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.149536594748497, 0.9410510063171387]"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see saving and loading our model with either format results in the same performance.\n",
        "\n",
        "🤔 Question: Should you used the SavedModel format or HDF5 format?\n",
        "\n",
        "For most use cases, the SavedModel format will suffice. However, this is a TensorFlow specific standard. If you need a more general-purpose data standard, HDF5 might be better."
      ],
      "metadata": {
        "id": "V8Wf0vcPkRqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finding the most wrong examples"
      ],
      "metadata": {
        "id": "f0nya5S5kX9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataframe with validation sentences and best performing model predictions\n",
        "val_df = pd.DataFrame({\"text\": val_sentences,\n",
        "                       \"target\": val_labels,\n",
        "                       \"pred\": model_6_preds,\n",
        "                       \"pred_prob\": tf.squeeze(model_6_pred_probs)})\n",
        "val_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eNmBieIfkNqs",
        "outputId": "980bf6e9-5e23-4ca4-e098-571a343d5213"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  target  pred  pred_prob\n",
              "0  This review is for Wynn Fitness Richmond Hill,...       1   1.0   0.985186\n",
              "1  Great little dive with cheap drinks. The Burge...       1   1.0   0.999029\n",
              "2  The pho it's self isn't bad at all, very littl...       0   0.0   0.053304\n",
              "3  I love going there when I want to host a nice ...       1   1.0   0.999842\n",
              "4  I ordered and after 40 minutes I get a text th...       0   0.0   0.052791"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7bc2c2f7-31e8-4a91-9ef8-caa39f23b135\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This review is for Wynn Fitness Richmond Hill,...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.985186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Great little dive with cheap drinks. The Burge...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.999029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The pho it's self isn't bad at all, very littl...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.053304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I love going there when I want to host a nice ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.999842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I ordered and after 40 minutes I get a text th...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.052791</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7bc2c2f7-31e8-4a91-9ef8-caa39f23b135')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7bc2c2f7-31e8-4a91-9ef8-caa39f23b135 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7bc2c2f7-31e8-4a91-9ef8-caa39f23b135');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the wrong predictions and sort by prediction probabilities\n",
        "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_prob\", ascending=False)\n",
        "most_wrong[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "nWHg6exVkaN6",
        "outputId": "1ce06f35-1cd5-40aa-88bf-d7052718d869"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  target  pred  \\\n",
              "1907  Used to be good 10 years ago until recently (2...       0   1.0   \n",
              "687   Good wings. But be prepared to pay extra for r...       0   1.0   \n",
              "4465  Coffee cake is always good. I usually order my...       0   1.0   \n",
              "4971  Update 4/11/13-- Since they have opened their ...       0   1.0   \n",
              "7847  Generic menu (salads, burgers, and steak). Hig...       0   1.0   \n",
              "336   I do love me some Dairy Queen but this particu...       0   1.0   \n",
              "1665  Update:\\nThis used to be my fav Thai place but...       0   1.0   \n",
              "2233  I came in for a couples massage for my birthda...       0   1.0   \n",
              "3664  Free cookie if you check in with yelp!  YES pl...       0   1.0   \n",
              "6064  J'adore la cuisine indienne; c'est probablemen...       0   1.0   \n",
              "\n",
              "      pred_prob  \n",
              "1907   0.998809  \n",
              "687    0.997459  \n",
              "4465   0.996993  \n",
              "4971   0.996796  \n",
              "7847   0.994691  \n",
              "336    0.990768  \n",
              "1665   0.990643  \n",
              "2233   0.990457  \n",
              "3664   0.990412  \n",
              "6064   0.984982  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-514820b9-2ffd-4815-9345-bbe0aac43f9f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1907</th>\n",
              "      <td>Used to be good 10 years ago until recently (2...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.998809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>687</th>\n",
              "      <td>Good wings. But be prepared to pay extra for r...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.997459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4465</th>\n",
              "      <td>Coffee cake is always good. I usually order my...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.996993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4971</th>\n",
              "      <td>Update 4/11/13-- Since they have opened their ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.996796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7847</th>\n",
              "      <td>Generic menu (salads, burgers, and steak). Hig...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.994691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>336</th>\n",
              "      <td>I do love me some Dairy Queen but this particu...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.990768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1665</th>\n",
              "      <td>Update:\\nThis used to be my fav Thai place but...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.990643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2233</th>\n",
              "      <td>I came in for a couples massage for my birthda...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.990457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3664</th>\n",
              "      <td>Free cookie if you check in with yelp!  YES pl...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.990412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6064</th>\n",
              "      <td>J'adore la cuisine indienne; c'est probablemen...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.984982</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-514820b9-2ffd-4815-9345-bbe0aac43f9f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-514820b9-2ffd-4815-9345-bbe0aac43f9f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-514820b9-2ffd-4815-9345-bbe0aac43f9f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the false positives (model predicted 1 when should've been 0)\n",
        "for row in most_wrong[:10].itertuples(): # loop through the top 10 rows (change the index to view different rows)\n",
        "  _, text, target, pred, prob = row\n",
        "  print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n",
        "  print(f\"Text: {text}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxNX4Z3TkcDE",
        "outputId": "a3ceb79b-9a75-4465-e009-3ab5a6a9fba9"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0, Pred: 1, Prob: 0.9988094568252563\n",
            "Text: Used to be good 10 years ago until recently (2013-present) frequent visits all left us with the same souvenir, tummy-aches after we got home.\n",
            "\n",
            "Lots of Chinese celebrations here for mid-summer autumn and the new year. Is always booked for parties. \n",
            "\n",
            "Large selection of food and drinks. Decorated western-styled. Parking is a breeze.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.9974588751792908\n",
            "Text: Good wings. But be prepared to pay extra for ranch celery...really anything sloppy ex sauce.anything custom. Service..ok. Close early so not a place to chill after like 1030. And owners are always hovering over the bartenders so if you have more than a couple drinks you will be cut off. Good points....it's clean. Food is good. Andre is awesome.  Tonya is amazing to her customers.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.996992826461792\n",
            "Text: Coffee cake is always good. I usually order my usual, country fried chicken steak and eggs with gravy...:) Vegas doesn't have much breakfast places...this suffice the cravings....nothing fancy...more like your fancier version of denny's.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.9967960715293884\n",
            "Text: Update 4/11/13-- Since they have opened their airport location, they have changed a lot. They do not serve the same sandwiches anymore and almost everything is re-cooked/-pre-ready to go. Not as fresh and nice as it used to be. Sadly, we will not be visiting anymore since our favorite sandwiches are gone and not made to order as before. \n",
            "\n",
            "\n",
            "\n",
            "We have been HUGE fans of Tammie Coe Cakes. It's been at least 3 years that we often get a treat here. Our must haves are the BLT sandwich, everything cookie, blackberry bran muffin (to die for!!) and some other sandwiches that I can't remember their names. \n",
            "\n",
            "They sell all sort of yummy treats. We have enjoyed 90% of everything we have had the last few years. \n",
            "\n",
            "I had a hot chocolate once that was horrible. So I can't comment on the drinks much but their hot chocolate was really terrible. \n",
            "\n",
            "For thanksgiving we order a couple of pies the pecan and the apple one. For some reason when we tried them at the store (small size) they were good, but the big ones were not so good. :( They were good at the store but not the big ones we brought home. We won't try that again. \n",
            "\n",
            "Tammie Coe is expensive, otherwise we would visit more often. \n",
            "\n",
            "It's a great place to get a nice treat. They are super busy in the mornings. \n",
            "\n",
            "The staff is very friendly but not very knowledgeable about allergies or ingredients. \n",
            "\n",
            "The breads are very good too. I have tried a few loaves. However, they go bad or hard super fast. Each time was within a day or two. \n",
            "\n",
            "Tammie is the place to go for small items, simple light lunch or dinner, a treat here or there. We will keep coming as we have figure out our favorites!\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.9946913123130798\n",
            "Text: Generic menu (salads, burgers, and steak). Highly over priced steak for the quality of the cut and meal. The foods ok here. The restaurants at a nice spot with a great view of the lake. Make sure you walk all the way to side of the restaurant and sit by the bay window.\n",
            "\n",
            "Looks like there was only one server for the whole restaurant during lunch. Props to the lady giving us good service.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.9907676577568054\n",
            "Text: I do love me some Dairy Queen but this particular location always seems to be jam packed with not enough staff to accommodate demand.\n",
            "\n",
            "There is a nice patio to sit on outside which is cool, I just wish they stocked the napkin dispenser consistently....\n",
            "\n",
            "With that said, try the dipped cone or Skor blizzard - yummy!!\n",
            "\n",
            "Yay!! Dairy Queen!!\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.9906429648399353\n",
            "Text: Update:\n",
            "This used to be my fav Thai place but after my order today of What was supposed to be Basil Crispy Pork belly, I'm highly disappointed. I have posted a pic here of what should be the crispy meat but is NOTHING but fat. There were maybe three pieces of actual pork that I could eat and NOTHING was crispy. Don't think I'll be back, I paid $14.95 for fat.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Every time I get take out, I try something new. Everything is delicious but ommmmmg today, I tried the spicy basil crispy pork and can I just say wow! It was the most delicious dish I've had in a very long time a. The service is always top notch and quick. I definitely recommend this place!\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.9904566407203674\n",
            "Text: I came in for a couples massage for my birthday yesterday (12/14). My therapist was Kyra and my fiancé's therapist was Sarah. I've been frequenting this spa for many years and always receive a great massage & great service, hence why I always come back. Kerry is great, Heather is great and my fiancé said that Sarah was great. Unforunately, yesterday was one of the worst massages I've ever had. :( It felt very rushed and didn't quite feel like a \"professional\" massage. I think my therapist Kyra forgot to trim her nails because I could feel her nails digging into the back of my neck and that's all I could think about. I always get deep tissue massages so my pain tolerance is high. I carry a lot of tension in my shoulders and neck area and we both have issues with our sciatic. After my massage, I asked Kyra of possible techniques that I could do to alleviate some of the tension and her best reply was \"to drink water or lots of lemon water\". Thankfully, Sarah was very helpful and literally showed us a few good stretches to help other than drinking lemon water. In addition, hours after my massage, I had a little discomfort in the back of my neck. I had my fiancé look at the back of my neck and he saw a pretty decent size scratch on my neck, from where Kyra was digging with her nails. \n",
            "\n",
            "In addition, they forgot to give us locals discount and the bottled waters were warm, there was no ice and the bins for the robes and towels were overflowing. I'm not sure if management has changed recently, but this place needs some TLC. I'm going to try the M Resort for my next service. I hear great things about them.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.9904120564460754\n",
            "Text: Free cookie if you check in with yelp!  YES please.  I got the vegan peanut butter cookie which was wonderful.  I made the mistake of getting a donut though and it was no bueno. :(  I'm sure they have other tasty items but I struck out big time!\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.9849822521209717\n",
            "Text: J'adore la cuisine indienne; c'est probablement une de mes préférées. Par contre, je suis critique quand j'en mange.\n",
            "\n",
            "J'ai goûté la soupe dahl (très salée), les entrées variées (oignon baji, poulet tikka, samosa). Les bajis étaient plutôt tièdes. Le riz biryani à l'agneau était correct, mais sans plus. J'en cuisine un bien meilleur, sans me vanter! J'ai terminé le repas par un thé masala.\n",
            "\n",
            "Le service était gentil et attentif. Dommage, ce n'est pas le meilleur restaurant indien en ville.\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the most wrong false negatives (model predicted 0 when should've predict 1)\n",
        "for row in most_wrong[-10:].itertuples():\n",
        "  _, text, target, pred, prob = row\n",
        "  print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jVKY5-Xkg5q",
        "outputId": "1cc8ee52-1d90-4fc4-9bd7-aec7985fd73c"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 1, Pred: 0, Prob: 0.020968636497855186\n",
            "Text:\n",
            "I had the tropical crepes and my husband had the country skillet. The food was good. The coffee was fresh and hot, and they have flavored creamers. The service was a little slow, but not horrible. I was surprised that it wasn't packed on a Sunday at noon. My biggest complaint was that it was really really hot in there. Like, profusely sweating. We thought it may be because we were seated by a window, but I asked other patrons sitting across the restaurant and they were just as hot as us. I'd almost drop it to 3 stars because of that, but I'm willing to give them one more chance because the food was good.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.02077692374587059\n",
            "Text:\n",
            "I am leaving feedback today because of the previous reviews I read. I have been going here on and off for the past 5-6 years.  I have sprayed tan which the dark isn't really dark and it didn't last long (maybe my skin oils?) so I was having to come back every 2 days so I switched back to regular tanning.  Everyone that I have had interaction with is friendly, professional, and once we start talking they become extremely friendly regarding their personal life. I enjoy talking to all of them when I go in. The only time I was some what unhappy after my interaction (and it really wasn't a big deal) was when I was switching back from the spray tan membership to the regular membership and the person gave me incorrect info. I knew different which is the only reason I knew what she told me was incorrect.  As far as the bed not being cleaned until you get there that has happened a couple times but they went and cleaned it right away. Maybe caused a couple minute delay but come on if your cutting your time that close then you probably shouldn't be trying to fit tanning in right then. Plus you don't know what led up to that chain of events there could possibly be a good reason for that.  Give the girls a break......it's really not that big of a deal.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.019388476386666298\n",
            "Text:\n",
            "Pleasantly Surprised.... I am editing my original review that you can read below.  I was contacted by the manager of this location today.  I must say I'm very surprised.  Not only did he reach out to me on his own to listen to my concern, he was able to correct the problem with the prepaid gas issue.  He also valued me as a Customer and wanted to win my business back.  He offered me a credit for my next visit to Advantage.  I was never going to use them again, but after this call and the concern for a Customer, I will let them prove me wrong and hopefully change my next experience with them.  \n",
            "\n",
            "\n",
            "\n",
            "Do not use this place,  besides hidden fees and cars they say you're going to receive does not match what you get this place straight up lies to you.  The person at the desk told me to do the prepaid gas.  I said no because I will not use the entire tank.  She then told me it's okay because they prorate and only charge you for what you use.  Of course upon return the person that received car said prorating is not something they do.  Once again DO NOT USE THIS COMPANY!!!\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.01878579705953598\n",
            "Text:\n",
            "The food was divine.  I took away one star for the attitude.  We didn't have a reservation so we inquired as to availability on a lark as we walked by and were intrigued by the menu. Acting as though it were a hardship, the hostess grudgingly seated us at the (empty) bar.  When we left, there were still empty tables.  The service we got from the bartender herself was just fine.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.01781669445335865\n",
            "Text:\n",
            "We decided to go on a week night verse the weekend hoping it wouldn't be busy but there still a line out of the door when we arrived. The line moved pretty quickly, it didnt seem like we waited for very long. I thought it was going to be a rip off, high priced + low quantity & quality, but I was so wrong!!! It looked like a small amount of icecream when poured, chopped up, and spread out but once it was in the cup and eating it, there was plenty and it was soooo delicious!!! I would definitely go back!!\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.015934187918901443\n",
            "Text:\n",
            "The food was delicious but the service was pretty lacking. Took forever to get refills and had to ask a different server for items we asked our waitress for. The Italian lemon cake taste very similar to macaroni grills but isn't as moist.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.01554423850029707\n",
            "Text:\n",
            "Best 'in store' service in the Valley. Not pretentious or pushy but very patient staff. Ordered Mizuno irons through Vans. Told likely a week or less but it is now more than a week. Not a Vans problem but definitely a Mizuno problem. I contacted Mizuno customer service to follow up but no response. Asked Vans to do the same and they were told \"today\"... still no clubs... not Vans fault but I definitely would not order Mizuno irons again. Very frustrating disappointing- will cancel order tomorrow.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.01007906161248684\n",
            "Text:\n",
            "this restaurant used to be really really good. i don't know what happened here. we had the mushrooms and they were terrible - the blue cheese took over the delicate wild favors. the tacos were soggy and flavors bland. the chef likes hot spices with out knowledge of how combine contrasting nuance. bartender guy was rude and told me that the kitchen was closed when i wanted to order desert. This Cleveland establishment has is somethings to learn about attitude. Good luck!\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.0080711143091321\n",
            "Text:\n",
            "What's that in my KUNG PAO CHICKEN takeout?\n",
            "\n",
            "In the large-size black plastic container, I see a beautiful and bright assortment of green pepper and red pepper chunks, nice-sized wedges of large mushrooms, some water chestnut slices, and big plump peanuts, all swimming in an redolently inviting dark brown sauce. m-m-m.\n",
            "\n",
            "Wait a minute...something's missing.\n",
            "\n",
            "Green Pepper . . . . check\n",
            "Red Pepper . . . . . . check\n",
            "Mushrooms . . . . . . check\n",
            "Water Chestnuts. . check\n",
            "Peanuts . . . . . . . . . check\n",
            "\n",
            "Ah-hah...THERE you are..\n",
            "With a serving spoon, found the very few pieces of chicken.  (Embarrassed at the poor impression they were making in this namesake dish, they were all hiding underneath.)  The Focal Points.  The Stars of this dish.  The Main Ingredients.  What this is NAMED after---or so I'd always thought.  \n",
            "\n",
            "Shocking how little chicken was present---much less than the equivalent of a very small breast.  Not nearly enough for even two toddler appetites.  This was as close to a vegetarian dish as I've ever had without specifically ordering vegetarian.  Vegetables were fresh and flavorful...sauce quite delicious with just the right amount of heat...but more like KUNG PAO GREEN PEPPER with a chicken garnish.\n",
            "\n",
            "Called King Wah.  Now you have to understand what I'm like.  I very rarely complain, and if I do, it's legitimate and not over something trivial, I'm calm, friendly, and never raise my voice.  I've made mistakes in my own kitchen, and understand how things can happen.  I explained the issue, said how good it was otherwise, and must surely have been an oversight.  The man said no problem---the next time I was in, I'd get a half order at no charge.   \n",
            "\n",
            "At that, a woman suddenly commandeers the phone, wanting to know what the problem was.  I started all over again...was interrupted a \"few\" times.  We went back and forth.  The woman INSISTED that there was \"a lot of chicken\" in it and that she packed it herself (repeated this at least three times.)  I asked her what the normal amount would be.  She had no answer---said she isn't the chef, but wanted to show him so he didn't make the mistake with other orders.  One time she said she saw all the chicken on the top, then another that it all was on the bottom.  (It was all on the bottom.)   An absolutely ridiculous conversation.   I told her this dish---of many Chinese chicken dishes I've ever had---had the least amount of chicken I'd ever seen.  \"Just bring it back.\"  That stubborn type who just refuses to believe, concede, apologize, no matter what or no matter who's on the other end.\n",
            "\n",
            "Okay...this is a stretch...but if this woman was alerted that she has a call from the White House itself, and our Commander in Chief...go with me on this...in the same mellow manner---as I tried my best to maintain---he brings the very meager quantity to her attention, and she quickly says, \"MR. PRESIDENT, there was a LOT of chicken in it!  A LOT of chicken!  I packed it MYSELF, Mr. President!\"  Just one of those people who dig in their heels and never back off, no matter how senseless.   \n",
            "\n",
            "She told me to bring it back for a refund.  I said I wasn't going back out tonight.  Then bring it back tomorrow.  I said that I probably couldn't.   Or the day after, she said, to show the chef (?)---to put it in the refrigerator until then.  Back and forth.   I'm getting a headache just writing this, and rather than giving one to you, let me put us both out of our misery by saying my Take-Out will soon be Take-Back.    \n",
            "\n",
            "As a footnote, the very tasty Pad Thai had a generous amount of chicken and shrimp. \n",
            "\n",
            "I'd rate both dishes as easy 4 stars for flavor, freshness, and ingredients,  despite the missing chicken pieces.  Where DID they go, anyway?  Simply vanished.  \n",
            "\n",
            "\"The Case of the Missing Chicken\". \n",
            "\n",
            "to be continued......\n",
            "\n",
            "4/3/2012 update.  What had started out as a principle issue, I soon realized was just too trivial to bother with.  For the missing dollars worth of chicken, I just ate it.  And it was still very good sans poultry.   Next time---I'll be smart---and eat in.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.00540510518476367\n",
            "Text:\n",
            "Terrible, this place is a joke the service is terrible the food is not fresh.. The food takes forever, they brought out our entree first and our appetizers last and we had to wait for our drinks for 20 mins.. If this tell the owners anything, I hope it's helps and is taken only constructively!\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictions on custom data"
      ],
      "metadata": {
        "id": "rV9J6xgqkwVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "review_1 = \"Horrible taste, wish I hadn't wasted my money here\"\n",
        "review_2 = \"Seems great, would definitely check out later.\"\n",
        "review_3 = \"The taste was just ok, not bad,not good.\"\n",
        "review_4 = \"Pie was amazing but beef didn't seem fresh, 6/10 in my opinion.\"\n",
        "review_5 = \"Food tasted good but the service was disgusting, waiters were late and the food wasn't served in time.\"\n",
        "review_6 = \"Service was neutral but the food was fresh, hot and tasty.\""
      ],
      "metadata": {
        "id": "lX-X9WRdknjW"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_prob = tf.squeeze(model_6.predict([review_1])) # has to be list\n",
        "pred = tf.round(pred_prob)\n",
        "print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-jxfWOwlr2w",
        "outputId": "73c87f46-96c4-405a-b437-cb19b1857a5c"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 0, Prob: 0.0009475264232605696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_and_prob_sentence(sentence):\n",
        "    pred_prob = tf.squeeze(model_6.predict([sentence])) # has to be list\n",
        "    pred = tf.round(pred_prob)\n",
        "    print(f\"Pred: {int(pred)}\", \"(positive review)\" if pred > 0 else \"(negative review)\", f\", Prob: {pred_prob}\")"
      ],
      "metadata": {
        "id": "IEC1ezaYl1Z4"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_and_prob_sentence(review_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD1SZQPWmIIP",
        "outputId": "c8823ede-1f1f-47d7-f5f7-afea0d0f12a8"
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 1 (positive review) , Prob: 0.9983795881271362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_and_prob_sentence(review_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgybrg5hmMQe",
        "outputId": "29a01e77-c3e4-4157-928b-b9195e820f40"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 0 (negative review) , Prob: 0.034002117812633514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_and_prob_sentence(review_4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP1M13Z3mPLm",
        "outputId": "2e5ab2d5-16e4-45cc-cbc0-84b087f04610"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 0 (negative review) , Prob: 0.347427636384964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_and_prob_sentence(review_5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7UqADAXmUpx",
        "outputId": "7d2b1bf5-50d3-4482-fa0e-911bdc617957"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 0 (negative review) , Prob: 0.008545465767383575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_and_prob_sentence(review_6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4s4VcvjZmXD2",
        "outputId": "b596d287-de91-4012-ff8a-240848774b93"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 1 (positive review) , Prob: 0.5346159338951111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bYWRxRMdmjj-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}